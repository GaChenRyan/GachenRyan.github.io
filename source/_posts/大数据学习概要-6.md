---
title: 大数据学习概要(6)
date: 2018-07-20 09:57:39
tags:
    - 大数据
    - RDD
---
## RDD
Spark 核心的概念是 Resilient Distributed Dataset (RDD)：一个可并行操作的有容错机制的数据集合。

<!-- more -->

RDD的依赖关系:  
![rdd_dependencies.jpg](/img/rdd_dependencies.jpg)  
RDD数据集通过“血缘关系”记住了它是如何从其它RDD中演变过来的，血缘关系记录的是粗颗粒度的转换操作行为，当这个RDD的部分分区数据丢失时，它可以通过血缘关系获取足够的信息来重新运算和恢复丢失的数据分区，由此带来了性能的提升。此外，Spark还提供了数据检查点和记录日志，用于持久化中间RDD，从而使得在进行失败恢复时不需要追溯到最开始的阶段。

RDD的创建方式：
* 从内存里直接读取数据：makeRDD、parallelize
* 从文件系统里读取

RDD操作：
* 转换(transformations) 从已经存在的数据集中创建一个新的数据集；
* 动作(actions) 在数据集上进行计算之后返回一个值到驱动程序。

![rdd_transformation.png](/img/rdd_transformation.png)   
![rdd_action.png](/img/rdd_action.png) 